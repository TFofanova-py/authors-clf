<h2>Тема</h2>
Определение авторства текста

<h2>Исполнитель, научный руководитель</h2>
Исполнитель - Фофанова Татьяна

Научный руководитель - Сергей Аксёнов

<h2>Постановка и описание задачи</h2>
Задача определения авторства решается применительно к текстам русских, советских и российских писателей XVIII – XXI веков. Это задача многоклассовой классификации, с непересекающимися классами.

Набор данных содержит произведения 38 писателей — повести, романы, пьесы, рассказы, публицистику, воспоминания, письма и т.п. Поэтические произведения в данной работе не рассматриваются.

Основная задача, решаемая в работе — задача классификации текстовых данных; кроме основной, в работе предполагается решить ряд сопутствующих задач — кластеризация авторов по стилю, выделение семантической составляющей текста, генерация текста в заданном стиле.
Ожидаемые результаты: 
- построение модели с использованием архитектуры трансформеров для классификации;
- интерпретация предсказаний классификатора и визуализация вклада токенов в предсказание;
- попытка переноса стиля выбранного автора на произвольный текст. 

<h2>Данные</h2>
В качестве исходных данных собраны произведения 38 авторов в EPUB-формате, список авторов и их произведений приводится в Приложении 1 (см. отчет).

Данные для обучения модели представляют собой отрывки произведений длиной не менее 2000 символов, состоящие из целых предложений.
В обучающую выборку вошли 178 томов и отдельных произведений, по ним были получены более 47 тыс. объектов; в тестовой выборке – 79 томов / произведений, более 18 тыс. объектов.

Обучающая и тестовая выборки не пересекаются по произведениям, т.е. все отрывки из каждого произведения находятся либо в обучающей, либо в тестовой выборке. Это позволит избежать завышения метрик качества из-за неправильного дизайна эксперимента.
Количество и объем произведений распределены по авторам неравномерно, наблюдается несбалансированность по классам.

Данные размещены в виде датасета на kaggle, их можно скачать с помощью kaggle API:

<pre><code>kaggle datasets download --unzip tatianafofanova/authorstexts</code></pre>

<h2>Baseline</h2>

В качестве базовой модели классификации текстов была выбрана модель BERT, обученная на большом корпусе русскоязычных текстов, и дообученная на примерах из собранного датасета. 

Для этого использовался класс AutoModelForSequenceClassification из библиотеки transformers, веса которой инициализировались из предобученной модели sberbank-ai/ruBert-base, размещенной на ресурсе huggingface.

Модель AutoModelForSequenceClassification представляет собой кодировщик BERT, состоящий из 12 слоев, и нескольких дополнительных слоев: слой dropout и линейный слой с 38 выходами, каждый из которых соответствует определенному автору.

Обучение модели проводилось в течение 5 эпох, с размером батча, равным 6. 

После каждой эпохи вычислялись метрики качества модели. Лучшая модель определялась по метрике F1-score с макро-усреднением, чтобы вклад каждого класса в метрику был одинаковым и не зависел от размера класса.

Базовая модель имеет F1-score  с макроусреднением, равный 0.74, и c микроусреднением — 0.78.

Логирование эксперимента проводилось с помощью сервиса WandB, сохраненной в виде артефакта моделью можно воспользоваться следующим образом:

<pre><code>run = wandb.init()
artifact = run.use_artifact('sava_ml/hw-nlp/baseline38:v1', type='model')
artifact_dir = artifact.download()
</code></pre>

<h2>Sentence-BERT (SBERT)</h2>

<a href=https://arxiv.org/abs/1908.10084>Ссылка на статью</a>

Обучение модели проводится с использованием фреймворка <a href=https://www.sbert.net>SentenceTransformers</a>

Проводится 2 эскперимента: 

1. Эмбеддинги текстов обучаются с помощью SentenceTransformers и используются в качестве признаков для классификатора. Классификатор и SBERT обучаются отдельно друг от друга.

Такой подход не дал улучшения в качестве классификации. F1-score с макроусреднением получился 0.70

2. SBERT и классификатор обучаются одновременно. Такой подход реализован в фреймворке - возможно обучать модель на решении нескольких задач одновременно. Но результат тот же -0.70.

<h2>Что дальше</h2>

- интерпретировать выходы модели с помощью интергрированных градиентов и библиотеки Captum

- перенос стиля: добавить механизм VAE в модель T5, вдохновившись <a href=https://arxiv.org/abs/2108.02446>статьей</a>


