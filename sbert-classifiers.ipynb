{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_kg_hide-output": true,
    "id": "v2_AO1EVY3oL"
   },
   "source": [
    "## Загрузим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T05:02:44.249897Z",
     "iopub.status.busy": "2023-03-19T05:02:44.249188Z",
     "iopub.status.idle": "2023-03-19T05:03:11.413390Z",
     "shell.execute_reply": "2023-03-19T05:03:11.412156Z",
     "shell.execute_reply.started": "2023-03-19T05:02:44.249847Z"
    }
   },
   "outputs": [],
   "source": [
    "! pip install evaluate\n",
    "! pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T05:03:11.416579Z",
     "iopub.status.busy": "2023-03-19T05:03:11.415746Z",
     "iopub.status.idle": "2023-03-19T05:03:12.022336Z",
     "shell.execute_reply": "2023-03-19T05:03:12.021149Z",
     "shell.execute_reply.started": "2023-03-19T05:03:11.416524Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T05:03:12.024611Z",
     "iopub.status.busy": "2023-03-19T05:03:12.024241Z",
     "iopub.status.idle": "2023-03-19T05:03:17.310441Z",
     "shell.execute_reply": "2023-03-19T05:03:17.309179Z",
     "shell.execute_reply.started": "2023-03-19T05:03:12.024576Z"
    },
    "id": "BlZ9DlN9Y7_b"
   },
   "outputs": [],
   "source": [
    "ds_train = pd.read_csv(\"../input/authorstexts/train_data.csv\", usecols=[0, 2])\n",
    "ds_test = pd.read_csv(\"../input/authorstexts/test_data.csv\", usecols=[0, 2])\n",
    "\n",
    "ds_train = ds_train.sample(frac=1)\n",
    "ds_test = ds_test.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T05:03:17.318867Z",
     "iopub.status.busy": "2023-03-19T05:03:17.313891Z",
     "iopub.status.idle": "2023-03-19T05:03:17.335552Z",
     "shell.execute_reply": "2023-03-19T05:03:17.333966Z",
     "shell.execute_reply.started": "2023-03-19T05:03:17.318820Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((47162, 2), (18139, 2))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train.shape, ds_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T05:03:17.340877Z",
     "iopub.status.busy": "2023-03-19T05:03:17.340078Z",
     "iopub.status.idle": "2023-03-19T05:03:17.370657Z",
     "shell.execute_reply": "2023-03-19T05:03:17.369756Z",
     "shell.execute_reply.started": "2023-03-19T05:03:17.340833Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Akunin': 0,\n",
       " 'Averchenko': 1,\n",
       " 'Belyaev': 2,\n",
       " 'Bulgakov': 3,\n",
       " 'Bunin': 4,\n",
       " 'Chekhov': 5,\n",
       " 'Dostoevsky': 6,\n",
       " 'Dovlatov': 7,\n",
       " 'Fadeev': 8,\n",
       " 'Fray': 9,\n",
       " 'Furmanov': 10,\n",
       " 'Gaydar': 11,\n",
       " 'Gogol': 12,\n",
       " 'Goncharov': 13,\n",
       " 'Gorky': 14,\n",
       " 'Grin': 15,\n",
       " 'Ilf_petrov': 16,\n",
       " 'Kataev': 17,\n",
       " 'Kazantsev': 18,\n",
       " 'Kuprin': 19,\n",
       " 'Leskov': 20,\n",
       " 'Lukyanenko': 21,\n",
       " 'Ostrovsky': 22,\n",
       " 'Pasternak': 23,\n",
       " 'Paustovskiy': 24,\n",
       " 'Pelevin': 25,\n",
       " 'Pikul': 26,\n",
       " 'Prishvin': 27,\n",
       " 'Pushkin': 28,\n",
       " 'Saltykov-schedrin': 29,\n",
       " 'Serafimovich': 30,\n",
       " 'Sergeev-Thsenskiy': 31,\n",
       " 'Shukshin': 32,\n",
       " 'Solzhenitsin': 33,\n",
       " 'Struhgatskie': 34,\n",
       " 'Tolstoy': 35,\n",
       " 'Turgenev': 36,\n",
       " 'Zoschenko': 37}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wr2ids = {k: i for i, k in enumerate(sorted(ds_train.writer.unique()))}\n",
    "wr2ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T05:03:17.372667Z",
     "iopub.status.busy": "2023-03-19T05:03:17.372127Z",
     "iopub.status.idle": "2023-03-19T05:03:17.382124Z",
     "shell.execute_reply": "2023-03-19T05:03:17.375486Z",
     "shell.execute_reply.started": "2023-03-19T05:03:17.372633Z"
    }
   },
   "outputs": [],
   "source": [
    "ids2wr = {v: k for k, v in wr2ids.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T05:03:17.385287Z",
     "iopub.status.busy": "2023-03-19T05:03:17.383687Z",
     "iopub.status.idle": "2023-03-19T05:03:17.393593Z",
     "shell.execute_reply": "2023-03-19T05:03:17.392628Z",
     "shell.execute_reply.started": "2023-03-19T05:03:17.385253Z"
    },
    "id": "V7R7llPDU-8W"
   },
   "outputs": [],
   "source": [
    "ds_train.reset_index(drop=True, inplace=True)\n",
    "ds_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SBERT with Sentence-Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T05:03:17.395691Z",
     "iopub.status.busy": "2023-03-19T05:03:17.394986Z",
     "iopub.status.idle": "2023-03-19T05:03:25.551313Z",
     "shell.execute_reply": "2023-03-19T05:03:25.550190Z",
     "shell.execute_reply.started": "2023-03-19T05:03:17.395656Z"
    }
   },
   "outputs": [],
   "source": [
    "from sentence_transformers.readers import InputExample\n",
    "from sentence_transformers import SentenceTransformer, losses\n",
    "from sentence_transformers.datasets import SentenceLabelDataset\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T05:03:25.554297Z",
     "iopub.status.busy": "2023-03-19T05:03:25.553405Z",
     "iopub.status.idle": "2023-03-19T05:03:25.617300Z",
     "shell.execute_reply": "2023-03-19T05:03:25.616240Z",
     "shell.execute_reply.started": "2023-03-19T05:03:25.554255Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T05:03:25.623346Z",
     "iopub.status.busy": "2023-03-19T05:03:25.622684Z",
     "iopub.status.idle": "2023-03-19T05:03:34.807119Z",
     "shell.execute_reply": "2023-03-19T05:03:34.805872Z",
     "shell.execute_reply.started": "2023-03-19T05:03:25.623307Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cef019471b6049218f1ebb31b9c70d29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.77k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32ff0133eb364636846a37b57228b600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/7.36k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82019b5c6a9f47799026c78455ca1f9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/7.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "f1 = evaluate.load(\"f1\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    \n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    f1_macro = f1.compute(predictions=predictions, references=labels, average='macro')\n",
    "    f1_micro = f1.compute(predictions=predictions, references=labels, average='micro')\n",
    "    rec_macro = recall.compute(predictions=predictions, references=labels, average='macro')\n",
    "    rec_micro = recall.compute(predictions=predictions, references=labels, average='micro')\n",
    "    prec_macro = precision.compute(predictions=predictions, references=labels, average='macro')\n",
    "    prec_micro = precision.compute(predictions=predictions, references=labels, average='micro')\n",
    "    return {\"f1_macro\": f1_macro[\"f1\"], \"f1_micro\": f1_micro[\"f1\"], \n",
    "            \"recall_macro\": rec_macro[\"recall\"], \"recall_micro\": rec_micro[\"recall\"], \n",
    "            \"precision_macro\": prec_macro[\"precision\"], \"precision_micro\": prec_micro[\"precision\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-03-18T08:46:57.463045Z",
     "iopub.status.busy": "2023-03-18T08:46:57.461683Z",
     "iopub.status.idle": "2023-03-18T08:47:06.981716Z",
     "shell.execute_reply": "2023-03-18T08:47:06.980683Z",
     "shell.execute_reply.started": "2023-03-18T08:46:57.462993Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86bbe811fd684e54953839fbfad440cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)bb2a0/.gitattributes:   0%|          | 0.00/690 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdcea19ac9d64bf5955b7065015d6d2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)34f3cbb2a0/README.md:   0%|          | 0.00/392 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5d31ab59f7743baa0262d9988a71780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)f3cbb2a0/config.json:   0%|          | 0.00/590 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e1c7104c9fc45c896861942a689cca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/716M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aff296fca00c42bd9aff71d7278dd6a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)34f3cbb2a0/vocab.txt:   0%|          | 0.00/1.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /root/.cache/torch/sentence_transformers/sberbank-ai_ruBert-base were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "huggingface_name = \"sberbank-ai/ruBert-base\"\n",
    "model = SentenceTransformer(huggingface_name)\n",
    "\n",
    "train_loss = losses.BatchHardTripletLoss(model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обучения модели используется триплетная функция потерь. Для ее вычисления требуется 3 объекта из датасета: якорь, позитивный пример (пример текста того же класса, что и якорь), и негативный пример (пример текста другого класса).\n",
    "\n",
    "Для обучения модели создадим объект SentenceLabelDataset, который принимает на вход тексты и метки классов для них и формирует из них тройки - якорь, позитивный и негативный примеры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T13:24:03.277238Z",
     "iopub.status.busy": "2023-03-07T13:24:03.276843Z",
     "iopub.status.idle": "2023-03-07T13:24:03.728280Z",
     "shell.execute_reply": "2023-03-07T13:24:03.727251Z",
     "shell.execute_reply.started": "2023-03-07T13:24:03.277205Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "train_examples = [InputExample(texts=[t], label=wr2ids[l]) for t, l in zip(ds_train.text, ds_train.writer)]\n",
    "\n",
    "train_dataset = SentenceLabelDataset(train_examples)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для оценки качества модели нужен похожий объект, но в виде словаря. Для этого напишем класс TripletDataset, который возвращает словарь с объектами для тестирования качества модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-11T12:08:28.974005Z",
     "iopub.status.busy": "2023-03-11T12:08:28.973608Z",
     "iopub.status.idle": "2023-03-11T12:08:28.982864Z",
     "shell.execute_reply": "2023-03-11T12:08:28.981849Z",
     "shell.execute_reply.started": "2023-03-11T12:08:28.973961Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class TripletDataset(Dataset):\n",
    "    def __init__(self, df, return_input_example=False):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.return_input_example = return_input_example\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ancor_idx = self.df.iloc[idx]\n",
    "        pos_idx = self.df[self.df.writer == ancor_idx.writer].sample(n=1).iloc[0]\n",
    "        neg_idx = self.df[self.df.writer != ancor_idx.writer].sample(n=1).iloc[0]\n",
    "\n",
    "        if self.return_input_example:\n",
    "            return InputExample(texts=[ancor_idx.text.lower(), pos_idx.text.lower(), neg_idx.text.lower()])\n",
    "        \n",
    "        return {\"ancor\": ancor_idx.text.lower(), \\\n",
    "            \"pos\": pos_idx.text.lower(), \\\n",
    "            \"neg\": neg_idx.text.lower()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "test_triplets_dataset = TripletDataset(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-11T12:08:28.984915Z",
     "iopub.status.busy": "2023-03-11T12:08:28.984306Z",
     "iopub.status.idle": "2023-03-11T12:09:55.416033Z",
     "shell.execute_reply": "2023-03-11T12:09:55.414993Z",
     "shell.execute_reply.started": "2023-03-11T12:08:28.984874Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "test_ancors, test_pos, test_neg = [], [], []\n",
    "for ex in test_triplets_dataset:\n",
    "    test_ancors.append(ex[\"ancor\"])\n",
    "    test_pos.append(ex[\"pos\"])\n",
    "    test_neg.append(ex[\"neg\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель на тренировочных данный с использованием функции потерь BatchHardTripletLoss, которая подбирает батчи так, чтобы в них попадали наиболее сложные для модели сочетания якоря и позитивных/негативных примеров.\n",
    "\n",
    "Оценка качества будет проводится с помощью доли примеров, для которых расстояние между якорем и позитивным примером меньше, чем соответствующее расстояние от негативного примера."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-07T13:21:53.890863Z",
     "iopub.status.idle": "2023-03-07T13:21:53.891349Z",
     "shell.execute_reply": "2023-03-07T13:21:53.891133Z",
     "shell.execute_reply.started": "2023-03-07T13:21:53.891097Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import evaluation\n",
    "\n",
    "evaluator = evaluation.TripletEvaluator(test_ancors, test_pos, test_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "model.fit([(train_dataloader, train_loss)], show_progress_bar=True, epochs=2, \n",
    "          evaluator=evaluator, evaluation_steps=3000, output_path=\"sbert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраним модель в виде артефакта wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T09:35:43.721313Z",
     "iopub.status.busy": "2023-03-07T09:35:43.720073Z",
     "iopub.status.idle": "2023-03-07T09:35:43.729355Z",
     "shell.execute_reply": "2023-03-07T09:35:43.728479Z",
     "shell.execute_reply.started": "2023-03-07T09:35:43.721135Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"Diploma\")\n",
    "\n",
    "artifact = wandb.Artifact('sbert', type='model')\n",
    "artifact.add_dir('sbert/')\n",
    "wandb.log_artifact(artifact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценка качества получившейся модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T05:03:34.809347Z",
     "iopub.status.busy": "2023-03-19T05:03:34.808511Z",
     "iopub.status.idle": "2023-03-19T05:05:08.378325Z",
     "shell.execute_reply": "2023-03-19T05:05:08.377031Z",
     "shell.execute_reply.started": "2023-03-19T05:03:34.809305Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ········································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20230319_050359-9id6jnz6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sava_ml/uncategorized/runs/9id6jnz6' target=\"_blank\">fanciful-pond-49</a></strong> to <a href='https://wandb.ai/sava_ml/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sava_ml/uncategorized' target=\"_blank\">https://wandb.ai/sava_ml/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sava_ml/uncategorized/runs/9id6jnz6' target=\"_blank\">https://wandb.ai/sava_ml/uncategorized/runs/9id6jnz6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact sbert:v2, 685.50MB. 12 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   12 of 12 files downloaded.  \n",
      "Done. 0:0:36.0\n"
     ]
    }
   ],
   "source": [
    "run = wandb.init()\n",
    "artifact = run.use_artifact('sava_ml/uncategorized/sbert:v2', type='model')\n",
    "artifact_dir = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T09:41:31.829717Z",
     "iopub.status.busy": "2023-03-07T09:41:31.829216Z",
     "iopub.status.idle": "2023-03-07T09:41:36.147284Z",
     "shell.execute_reply": "2023-03-07T09:41:36.146059Z",
     "shell.execute_reply.started": "2023-03-07T09:41:31.829665Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "model = SentenceTransformer('artifacts/sbert:v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T09:44:38.867716Z",
     "iopub.status.busy": "2023-03-07T09:44:38.867149Z",
     "iopub.status.idle": "2023-03-07T10:01:55.535115Z",
     "shell.execute_reply": "2023-03-07T10:01:55.532050Z",
     "shell.execute_reply.started": "2023-03-07T09:44:38.867678Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "embeddings_anchors = model.encode(test_ancors, batch_size=8, show_progress_bar=False, convert_to_numpy=True)\n",
    "embeddings_positives = model.encode(test_pos, batch_size=8, show_progress_bar=False, convert_to_numpy=True)\n",
    "embeddings_negatives = model.encode(test_neg, batch_size=8, show_progress_bar=False, convert_to_numpy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-07T10:01:55.545906Z",
     "iopub.status.busy": "2023-03-07T10:01:55.543669Z",
     "iopub.status.idle": "2023-03-07T10:01:55.928557Z",
     "shell.execute_reply": "2023-03-07T10:01:55.927406Z",
     "shell.execute_reply.started": "2023-03-07T10:01:55.545868Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля объектов с правильным соотношением расстояний: 0.9658746347648712\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import paired_cosine_distances\n",
    "\n",
    "pos_cos_distances = paired_cosine_distances(embeddings_anchors, embeddings_positives)\n",
    "neg_cos_distances = paired_cosine_distances(embeddings_anchors, embeddings_negatives)\n",
    "\n",
    "print(\"Доля объектов с правильным соотношением расстояний:\",(pos_cos_distances < neg_cos_distances).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificator on SBERT\n",
    "\n",
    "Теперь обучим классификатор, который будет получать на вход эмбеддинги текстов, полученные с помощью предыдущей модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T05:05:08.381731Z",
     "iopub.status.busy": "2023-03-19T05:05:08.380820Z",
     "iopub.status.idle": "2023-03-19T05:05:08.393187Z",
     "shell.execute_reply": "2023-03-19T05:05:08.391925Z",
     "shell.execute_reply.started": "2023-03-19T05:05:08.381682Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, feature_extractor: SentenceTransformer, n_classes: int, label2ids: dict, emb_dim: int = 768):\n",
    "        super().__init__()\n",
    "        self.sbert = feature_extractor\n",
    "        self.sbert.requires_grad = False\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.fc = nn.Linear(emb_dim, n_classes)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        self.label2ids = label2ids\n",
    "        \n",
    "    def forward(self, text, label):\n",
    "        emb = self.sbert.encode(text, convert_to_tensor=True, show_progress_bar=False)\n",
    "            \n",
    "        out = self.dropout(emb)\n",
    "        out = self.fc(out)\n",
    "        logits = F.log_softmax(out, dim=-1)\n",
    "        \n",
    "        loss = self.loss(logits, label.cuda())\n",
    "        return loss, logits                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T05:05:08.394644Z",
     "iopub.status.busy": "2023-03-19T05:05:08.394304Z",
     "iopub.status.idle": "2023-03-19T05:05:08.408564Z",
     "shell.execute_reply": "2023-03-19T05:05:08.407010Z",
     "shell.execute_reply.started": "2023-03-19T05:05:08.394608Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T05:05:08.410994Z",
     "iopub.status.busy": "2023-03-19T05:05:08.410510Z",
     "iopub.status.idle": "2023-03-19T05:05:15.098636Z",
     "shell.execute_reply": "2023-03-19T05:05:15.097371Z",
     "shell.execute_reply.started": "2023-03-19T05:05:08.410960Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_extractor = SentenceTransformer('artifacts/sbert:v2').to(device)\n",
    "classifier = Classifier(feature_extractor, n_classes=38, label2ids=wr2ids).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T05:05:15.101016Z",
     "iopub.status.busy": "2023-03-19T05:05:15.100432Z",
     "iopub.status.idle": "2023-03-19T05:05:15.141366Z",
     "shell.execute_reply": "2023-03-19T05:05:15.140200Z",
     "shell.execute_reply.started": "2023-03-19T05:05:15.100978Z"
    }
   },
   "outputs": [],
   "source": [
    "class TextDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, df, label2ids):\n",
    "    super().__init__()\n",
    "    self.texts = df.text\n",
    "    self.labels = df.writer.apply(lambda w: label2ids[w])\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.texts.iloc[idx], torch.Tensor([self.labels.iloc[idx]]).long()\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.labels)\n",
    "\n",
    "train_dataset = TextDataset(ds_train, wr2ids)\n",
    "test_dataset = TextDataset(ds_test, wr2ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T05:05:15.148326Z",
     "iopub.status.busy": "2023-03-19T05:05:15.146289Z",
     "iopub.status.idle": "2023-03-19T05:05:15.155432Z",
     "shell.execute_reply": "2023-03-19T05:05:15.153170Z",
     "shell.execute_reply.started": "2023-03-19T05:05:15.148289Z"
    }
   },
   "outputs": [],
   "source": [
    " def example_collator(example_list):\n",
    "   \n",
    "    batched_examples = {\"text\": [ex[0] for ex in example_list], \"label\": torch.tensor([ex[1] for ex in example_list])} \n",
    "    return batched_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T05:05:15.159325Z",
     "iopub.status.busy": "2023-03-19T05:05:15.159017Z",
     "iopub.status.idle": "2023-03-19T05:05:15.190516Z",
     "shell.execute_reply": "2023-03-19T05:05:15.189130Z",
     "shell.execute_reply.started": "2023-03-19T05:05:15.159299Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "        output_dir=\"clf_trainer\",\n",
    "        evaluation_strategy=\"steps\",\n",
    "        eval_steps=3000,\n",
    "        per_device_train_batch_size=BATCH_SIZE,\n",
    "        per_device_eval_batch_size=BATCH_SIZE,\n",
    "        report_to=None,\n",
    "        num_train_epochs=3,\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=3000,\n",
    "        save_total_limit=2,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1_macro\"\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=classifier,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=example_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T05:05:15.197379Z",
     "iopub.status.busy": "2023-03-19T05:05:15.195468Z",
     "iopub.status.idle": "2023-03-19T06:23:18.840620Z",
     "shell.execute_reply": "2023-03-19T06:23:18.839457Z",
     "shell.execute_reply.started": "2023-03-19T05:05:15.197350Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:9id6jnz6) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ebd7a713aad4c488f396e9f5ac24f91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.016 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.069003…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fanciful-pond-49</strong> at: <a href='https://wandb.ai/sava_ml/uncategorized/runs/9id6jnz6' target=\"_blank\">https://wandb.ai/sava_ml/uncategorized/runs/9id6jnz6</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230319_050359-9id6jnz6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:9id6jnz6). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20230319_050515-i6ns2j2v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sava_ml/Diploma/runs/i6ns2j2v' target=\"_blank\">avid-cherry-59</a></strong> to <a href='https://wandb.ai/sava_ml/Diploma' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sava_ml/Diploma' target=\"_blank\">https://wandb.ai/sava_ml/Diploma</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sava_ml/Diploma/runs/i6ns2j2v' target=\"_blank\">https://wandb.ai/sava_ml/Diploma/runs/i6ns2j2v</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 47162\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17688\n",
      "  Number of trainable parameters = 178336550\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17688' max='17688' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17688/17688 1:17:25, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>Recall Macro</th>\n",
       "      <th>Recall Micro</th>\n",
       "      <th>Precision Macro</th>\n",
       "      <th>Precision Micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.240800</td>\n",
       "      <td>1.083274</td>\n",
       "      <td>0.693886</td>\n",
       "      <td>0.726115</td>\n",
       "      <td>0.709775</td>\n",
       "      <td>0.726115</td>\n",
       "      <td>0.734884</td>\n",
       "      <td>0.726115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.208300</td>\n",
       "      <td>1.133242</td>\n",
       "      <td>0.701601</td>\n",
       "      <td>0.731959</td>\n",
       "      <td>0.718067</td>\n",
       "      <td>0.731959</td>\n",
       "      <td>0.738050</td>\n",
       "      <td>0.731959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.182200</td>\n",
       "      <td>1.169020</td>\n",
       "      <td>0.699656</td>\n",
       "      <td>0.731793</td>\n",
       "      <td>0.717695</td>\n",
       "      <td>0.731793</td>\n",
       "      <td>0.737901</td>\n",
       "      <td>0.731793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.177900</td>\n",
       "      <td>1.191084</td>\n",
       "      <td>0.700800</td>\n",
       "      <td>0.732510</td>\n",
       "      <td>0.718661</td>\n",
       "      <td>0.732510</td>\n",
       "      <td>0.738915</td>\n",
       "      <td>0.732510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.171800</td>\n",
       "      <td>1.195446</td>\n",
       "      <td>0.701615</td>\n",
       "      <td>0.732896</td>\n",
       "      <td>0.718945</td>\n",
       "      <td>0.732896</td>\n",
       "      <td>0.739721</td>\n",
       "      <td>0.732896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 18139\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to clf_trainer/checkpoint-3000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 18139\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to clf_trainer/checkpoint-6000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 18139\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to clf_trainer/checkpoint-9000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Deleting older checkpoint [clf_trainer/checkpoint-3000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 18139\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to clf_trainer/checkpoint-12000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Deleting older checkpoint [clf_trainer/checkpoint-9000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 18139\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to clf_trainer/checkpoint-15000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Deleting older checkpoint [clf_trainer/checkpoint-6000] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from clf_trainer/checkpoint-15000 (score: 0.7016149416728183).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=17688, training_loss=0.2865021856377859, metrics={'train_runtime': 4647.1397, 'train_samples_per_second': 30.446, 'train_steps_per_second': 3.806, 'total_flos': 0.0, 'train_loss': 0.2865021856377859, 'epoch': 3.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"Diploma\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T06:23:18.842449Z",
     "iopub.status.busy": "2023-03-19T06:23:18.841982Z",
     "iopub.status.idle": "2023-03-19T06:23:28.719475Z",
     "shell.execute_reply": "2023-03-19T06:23:28.718360Z",
     "shell.execute_reply.started": "2023-03-19T06:23:18.842411Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to clf_trainer\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./clf_trainer)... Done. 8.5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<wandb.sdk.wandb_artifacts.Artifact at 0x7f3ea4dc9450>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(\"clf_trainer\")\n",
    "\n",
    "artifact = wandb.Artifact('sbert-clf', type='model')\n",
    "artifact.add_dir('clf_trainer/')\n",
    "wandb.log_artifact(artifact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценка качества классификации (раздельное обучение SBERT и классификатора)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(project=\"Diploma\")\n",
    "artifact = run.use_artifact('sava_ml/Diploma/sbert-clf:v0', type='model')\n",
    "artifact_dir = artifact.download()\n",
    "\n",
    "feature_extractor = SentenceTransformer('artifacts/sbert:v2')\n",
    "model = Classifier(feature_extractor, n_classes=38, label2ids=wr2ids)\n",
    "model.load_state_dict(torch.load('artifacts/sbert-clf:v0/checkpoint-15000/pytorch_model.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T06:29:12.478586Z",
     "iopub.status.busy": "2023-03-19T06:29:12.478218Z",
     "iopub.status.idle": "2023-03-19T06:35:13.907045Z",
     "shell.execute_reply": "2023-03-19T06:35:13.905982Z",
     "shell.execute_reply.started": "2023-03-19T06:29:12.478546Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 18139\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2268' max='2268' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2268/2268 06:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.1954458951950073,\n",
       " 'eval_f1_macro': 0.7016149416728183,\n",
       " 'eval_f1_micro': 0.7328959700093721,\n",
       " 'eval_recall_macro': 0.7189454475515519,\n",
       " 'eval_recall_micro': 0.7328959700093721,\n",
       " 'eval_precision_macro': 0.7397205518411758,\n",
       " 'eval_precision_micro': 0.7328959700093721,\n",
       " 'eval_runtime': 361.2154,\n",
       " 'eval_samples_per_second': 50.217,\n",
       " 'eval_steps_per_second': 6.279}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=example_collator\n",
    ")\n",
    "\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SBERT + классификатор одновременно\n",
    "\n",
    "Фреймворк SentenceTransformer позволяет обучать одновременно несколько моделей. \n",
    "\n",
    "В нашем случае нужно обучить SBERT формировать хорошие ембеддинги текстов и затем эти ембеддинги использовать в классификаторе. Для каждой из задач требуется своя функция потерь, обучающие данные при этом совпадают.\n",
    "\n",
    "При обучении классификатора мы будем настраивать функцию потерь так, чтобы градиент тек только через слои классификатора, но не через слои SBERT.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T06:35:43.888180Z",
     "iopub.status.busy": "2023-03-19T06:35:43.887675Z",
     "iopub.status.idle": "2023-03-19T06:35:43.909567Z",
     "shell.execute_reply": "2023-03-19T06:35:43.908468Z",
     "shell.execute_reply.started": "2023-03-19T06:35:43.888136Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sentence_transformers.readers import InputExample\n",
    "from sentence_transformers import SentenceTransformer, losses\n",
    "from sentence_transformers.datasets import SentenceLabelDataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import Trainer, TrainingArguments\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T06:35:47.688218Z",
     "iopub.status.busy": "2023-03-19T06:35:47.687821Z",
     "iopub.status.idle": "2023-03-19T06:35:47.696732Z",
     "shell.execute_reply": "2023-03-19T06:35:47.695425Z",
     "shell.execute_reply.started": "2023-03-19T06:35:47.688183Z"
    },
    "id": "swJg3S2D8JZr"
   },
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, n_classes: int, label2ids: dict, emb_dim: int = 768):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.fc = nn.Linear(emb_dim, n_classes)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        self.label2ids = label2ids\n",
    "        \n",
    "    def forward(self, sent_emb: torch.Tensor):          \n",
    "        out = self.dropout(sent_emb)\n",
    "        out = self.fc(out)\n",
    "        logits = F.log_softmax(out, dim=-1)\n",
    "        return logits\n",
    "    \n",
    "clf_model = Classifier(n_classes=38, label2ids=wr2ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T06:35:52.006344Z",
     "iopub.status.busy": "2023-03-19T06:35:52.005248Z",
     "iopub.status.idle": "2023-03-19T06:35:52.013812Z",
     "shell.execute_reply": "2023-03-19T06:35:52.012315Z",
     "shell.execute_reply.started": "2023-03-19T06:35:52.006305Z"
    }
   },
   "outputs": [],
   "source": [
    "class CrossEntropyClassificatorLoss(nn.Module):\n",
    "    def __init__(self, emb_model: nn.Module, clf_model: nn.Module):\n",
    "        super().__init__()\n",
    "        self.embeddings = emb_model\n",
    "        self.classifier = clf_model\n",
    "        \n",
    "    def forward(self, inp, label):\n",
    "        sent_emb = self.embeddings(inp[0])[\"sentence_embedding\"]\n",
    "        # sent_emb = self.embeddings.encode(inp, convert_to_tensor=True, show_progress_bar=False)\n",
    "        logits = self.classifier(sent_emb.detach())\n",
    "        \n",
    "        loss = self.classifier.loss(logits, label)\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_name = \"sberbank-ai/ruBert-base\"\n",
    "sbert_model = SentenceTransformer(huggingface_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(huggingface_name)\n",
    "sbert_model._model_config[\"label2id\"] = wr2ids\n",
    "sbert_model._model_config[\"id2label\"] = ids2wr\n",
    "\n",
    "triplet_loss = losses.BatchHardTripletLoss(model=sbert_model)\n",
    "\n",
    "ce_loss = CrossEntropyClassificatorLoss(emb_model=sbert_model, clf_model=clf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T06:36:54.708984Z",
     "iopub.status.busy": "2023-03-19T06:36:54.708619Z",
     "iopub.status.idle": "2023-03-19T06:36:54.715678Z",
     "shell.execute_reply": "2023-03-19T06:36:54.714622Z",
     "shell.execute_reply.started": "2023-03-19T06:36:54.708952Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def collate_tokenized_examples(examples: List[InputExample]):\n",
    "    tokenzed_list = [tokenizer(ex.texts, return_tensors=\"pt\", max_length=512, truncation=True, padding=\"max_length\") for ex in examples]\n",
    "    result = {\"input_ids\": torch.vstack([tok[\"input_ids\"] for tok in tokenzed_list]), \n",
    "              \"attention_mask\": torch.vstack([tok[\"attention_mask\"] for tok in tokenzed_list])}\n",
    "    result[\"label\"] = torch.tensor([ex.label for ex in examples])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T06:36:56.986659Z",
     "iopub.status.busy": "2023-03-19T06:36:56.985659Z",
     "iopub.status.idle": "2023-03-19T06:36:57.076481Z",
     "shell.execute_reply": "2023-03-19T06:36:57.075485Z",
     "shell.execute_reply.started": "2023-03-19T06:36:56.986590Z"
    }
   },
   "outputs": [],
   "source": [
    "train_examples = [InputExample(texts=[t], label=sbert_model._model_config[\"label2id\"][l]) for t, l in zip(ds_train.text, ds_train.writer)]\n",
    "\n",
    "train_dataset = SentenceLabelDataset(train_examples)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, collate_fn=collate_tokenized_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T06:36:58.967928Z",
     "iopub.status.busy": "2023-03-19T06:36:58.967245Z",
     "iopub.status.idle": "2023-03-19T06:36:59.382419Z",
     "shell.execute_reply": "2023-03-19T06:36:59.381349Z",
     "shell.execute_reply.started": "2023-03-19T06:36:58.967889Z"
    }
   },
   "outputs": [],
   "source": [
    "test_examples = [InputExample(texts=[t], label=sbert_model._model_config[\"label2id\"][l]) for t, l in zip(ds_test.text, ds_test.writer)]\n",
    "\n",
    "test_dataset = SentenceLabelDataset(test_examples)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8, collate_fn=collate_tokenized_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T06:37:00.977515Z",
     "iopub.status.busy": "2023-03-19T06:37:00.977000Z",
     "iopub.status.idle": "2023-03-19T06:37:15.988803Z",
     "shell.execute_reply": "2023-03-19T06:37:15.987642Z",
     "shell.execute_reply.started": "2023-03-19T06:37:00.977476Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 512])\n",
      "dict_keys(['input_ids', 'attention_mask', 'label', 'token_embeddings', 'sentence_embedding'])\n"
     ]
    }
   ],
   "source": [
    "# Проверка dataloader и sentence_transformers\n",
    "\n",
    "for ex in train_dataloader:\n",
    "    print(ex[\"input_ids\"].size())\n",
    "    print(sbert_model(ex).keys())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T06:37:26.039039Z",
     "iopub.status.busy": "2023-03-19T06:37:26.038005Z",
     "iopub.status.idle": "2023-03-19T06:37:26.047630Z",
     "shell.execute_reply": "2023-03-19T06:37:26.046169Z",
     "shell.execute_reply.started": "2023-03-19T06:37:26.039003Z"
    }
   },
   "outputs": [],
   "source": [
    "class SBERTClassifier(nn.Module):\n",
    "    def __init__(self, emb_model, clf_model):\n",
    "        super().__init__()\n",
    "        self.embeddings = emb_model\n",
    "        self.classifier = clf_model\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, tokenized_text, label=None):\n",
    "        # emb = self.embeddings.encode(tokenized_text, convert_to_tensor=True, show_progress_bar=False)\n",
    "        emb = self.embeddings((tokenized_text[0]))[\"sentence_embedding\"]\n",
    "        logits = self.classifier(emb)\n",
    "        \n",
    "        if label is None:\n",
    "            return None, {\"output\": logits}\n",
    "        \n",
    "        loss = self.loss(logits, label)\n",
    "        return loss, {\"output\": logits}\n",
    "\n",
    "full_model = SBERTClassifier(sbert_model, clf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T06:37:29.138967Z",
     "iopub.status.busy": "2023-03-19T06:37:29.138600Z",
     "iopub.status.idle": "2023-03-19T06:37:30.818478Z",
     "shell.execute_reply": "2023-03-19T06:37:30.817467Z",
     "shell.execute_reply.started": "2023-03-19T06:37:29.138934Z"
    }
   },
   "outputs": [],
   "source": [
    "from sentence_transformers.evaluation import SentenceEvaluator\n",
    "from sentence_transformers.util import batch_to_device\n",
    "import csv\n",
    "import os\n",
    "import evaluate\n",
    "\n",
    "class F1Evaluator(SentenceEvaluator):\n",
    "    \"\"\"\n",
    "    Evaluate a model based on its f1 score on a labeled dataset\n",
    "    This requires a model with LossFunction.SOFTMAX\n",
    "    The results are written in a CSV. If a CSV already exists, then values are appended.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataloader: DataLoader, name: str = \"\", softmax_model = None, write_csv: bool = True, mode=\"macro\"):\n",
    "        \"\"\"\n",
    "        Constructs an evaluator for the given dataset\n",
    "        :param dataloader:\n",
    "            the data for the evaluation\n",
    "        \"\"\"\n",
    "        self.dataloader = dataloader\n",
    "        self.name = name\n",
    "        self.softmax_model = softmax_model\n",
    "        self.f1 = evaluate.load(\"f1\")\n",
    "\n",
    "        if name:\n",
    "            name = \"_\" + name\n",
    " \n",
    "        self.write_csv = write_csv\n",
    "        self.csv_file = \"f1_evaluation_\" + mode + \"_\" + name +\"_results.csv\"\n",
    "        self.csv_headers = [\"epoch\", \"steps\", \"f1_\" + mode]\n",
    "        self.mode = mode\n",
    "\n",
    "    def __call__(self, model, output_path: str = None, epoch: int = -1, steps: int = -1) -> float:\n",
    "        model.eval()\n",
    "        self.softmax_model.eval()\n",
    "\n",
    "        if epoch != -1:\n",
    "            if steps == -1:\n",
    "                out_txt = \" after epoch {}:\".format(epoch)\n",
    "            else:\n",
    "                out_txt = \" in epoch {} after {} steps:\".format(epoch, steps)\n",
    "        else:\n",
    "            out_txt = \":\"\n",
    "\n",
    "        # logger.info(\"Evaluation on the \" + self.name + \" dataset\" + out_txt)\n",
    "        print(\"Evaluation on the \" + self.name + \" dataset\" + out_txt)\n",
    "        \n",
    "        self.dataloader.collate_fn = model.smart_batching_collate\n",
    "        \n",
    "        predictions, labels = [], []\n",
    "        \n",
    "        for step, batch in enumerate(self.dataloader):\n",
    "            features, label_ids = batch\n",
    "            \n",
    "            for idx in range(len(features)):\n",
    "                features[idx] = batch_to_device(features[idx], model.device)\n",
    "            \n",
    "            label_ids = label_ids.to(model.device)\n",
    "            with torch.no_grad():\n",
    "                logits = self.softmax_model(features)[1][\"output\"]\n",
    "                predictions.extend(torch.argmax(logits, dim=-1).tolist())\n",
    "                labels.extend(label_ids)\n",
    "                \n",
    "                \n",
    "        f1_macro = self.f1.compute(predictions=predictions, references=labels, average='macro')[\"f1\"]\n",
    "        f1_micro = self.f1.compute(predictions=predictions, references=labels, average='micro')[\"f1\"]\n",
    "\n",
    "       # logger.info(\"f1-macro: {:.4f}, f1-micro: {:.4f}\\n\".format(f1_macro, f1_micro)\n",
    "        print(\"f1-macro: {:.4f}, f1-micro: {:.4f}\\n\".format(f1_macro, f1_micro))\n",
    "        \n",
    "        f1 = f1_macro if self.mode == \"macro\" else f1_micro\n",
    "        \n",
    "        if output_path is not None and self.write_csv:\n",
    "            csv_path = os.path.join(output_path, self.csv_file)\n",
    "            if not os.path.isfile(csv_path):\n",
    "                with open(csv_path, newline='', mode=\"w\", encoding=\"utf-8\") as f:\n",
    "                    writer = csv.writer(f)\n",
    "                    writer.writerow(self.csv_headers)\n",
    "                    writer.writerow([epoch, steps, f1])\n",
    "            else:\n",
    "                with open(csv_path, newline='', mode=\"a\", encoding=\"utf-8\") as f:\n",
    "                    writer = csv.writer(f)\n",
    "                    writer.writerow([epoch, steps, f1])\n",
    "\n",
    "        return f1\n",
    "\n",
    "evaluator = F1Evaluator(test_dataloader, softmax_model=full_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T06:38:05.790100Z",
     "iopub.status.busy": "2023-03-19T06:38:05.789081Z",
     "iopub.status.idle": "2023-03-19T16:51:22.385676Z",
     "shell.execute_reply": "2023-03-19T16:51:22.384457Z",
     "shell.execute_reply.started": "2023-03-19T06:38:05.790034Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46c853e4035c4c7f9191c30ff54af5f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81b8df80b2e84fed9d34953035272763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/5896 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on the  dataset in epoch 0 after 3000 steps:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in sbert_clf_together/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-macro: 0.1065, f1-micro: 0.1638\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in sbert_clf_together/pytorch_model.bin\n",
      "tokenizer config file saved in sbert_clf_together/tokenizer_config.json\n",
      "Special tokens file saved in sbert_clf_together/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on the  dataset after epoch 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in sbert_clf_together/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-macro: 0.4275, f1-micro: 0.4643\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in sbert_clf_together/pytorch_model.bin\n",
      "tokenizer config file saved in sbert_clf_together/tokenizer_config.json\n",
      "Special tokens file saved in sbert_clf_together/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60ad0faa09564fcaa0ef2f8b90687ac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/5896 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on the  dataset in epoch 1 after 3000 steps:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in sbert_clf_together/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-macro: 0.5368, f1-micro: 0.5569\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in sbert_clf_together/pytorch_model.bin\n",
      "tokenizer config file saved in sbert_clf_together/tokenizer_config.json\n",
      "Special tokens file saved in sbert_clf_together/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on the  dataset after epoch 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in sbert_clf_together/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-macro: 0.6007, f1-micro: 0.6258\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in sbert_clf_together/pytorch_model.bin\n",
      "tokenizer config file saved in sbert_clf_together/tokenizer_config.json\n",
      "Special tokens file saved in sbert_clf_together/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b142e4619e344bd8a51abc92ed6d03cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/5896 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on the  dataset in epoch 2 after 3000 steps:\n",
      "f1-macro: 0.5666, f1-micro: 0.5856\n",
      "\n",
      "Evaluation on the  dataset after epoch 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in sbert_clf_together/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-macro: 0.6356, f1-micro: 0.6590\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in sbert_clf_together/pytorch_model.bin\n",
      "tokenizer config file saved in sbert_clf_together/tokenizer_config.json\n",
      "Special tokens file saved in sbert_clf_together/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2198c088a6ea4f63aebd499387d58a68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/5896 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on the  dataset in epoch 3 after 3000 steps:\n",
      "f1-macro: 0.5905, f1-micro: 0.5941\n",
      "\n",
      "Evaluation on the  dataset after epoch 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in sbert_clf_together/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-macro: 0.6442, f1-micro: 0.6594\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in sbert_clf_together/pytorch_model.bin\n",
      "tokenizer config file saved in sbert_clf_together/tokenizer_config.json\n",
      "Special tokens file saved in sbert_clf_together/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b068461b096a4eabb89f4e86e04000a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/5896 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on the  dataset in epoch 4 after 3000 steps:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in sbert_clf_together/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-macro: 0.6634, f1-micro: 0.6843\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in sbert_clf_together/pytorch_model.bin\n",
      "tokenizer config file saved in sbert_clf_together/tokenizer_config.json\n",
      "Special tokens file saved in sbert_clf_together/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on the  dataset after epoch 4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in sbert_clf_together/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-macro: 0.6754, f1-micro: 0.7073\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in sbert_clf_together/pytorch_model.bin\n",
      "tokenizer config file saved in sbert_clf_together/tokenizer_config.json\n",
      "Special tokens file saved in sbert_clf_together/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55aa4cb90c9f4186b7960aac016da683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/5896 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on the  dataset in epoch 5 after 3000 steps:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in sbert_clf_together/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-macro: 0.6888, f1-micro: 0.7136\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in sbert_clf_together/pytorch_model.bin\n",
      "tokenizer config file saved in sbert_clf_together/tokenizer_config.json\n",
      "Special tokens file saved in sbert_clf_together/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on the  dataset after epoch 5:\n",
      "f1-macro: 0.6840, f1-micro: 0.7044\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "263d17860c1a474ab4883dfe139346b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/5896 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on the  dataset in epoch 6 after 3000 steps:\n",
      "f1-macro: 0.6872, f1-micro: 0.7134\n",
      "\n",
      "Evaluation on the  dataset after epoch 6:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in sbert_clf_together/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-macro: 0.6934, f1-micro: 0.7164\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in sbert_clf_together/pytorch_model.bin\n",
      "tokenizer config file saved in sbert_clf_together/tokenizer_config.json\n",
      "Special tokens file saved in sbert_clf_together/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "461f5a3daaab49f7a0624adf60fe0ddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/5896 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on the  dataset in epoch 7 after 3000 steps:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in sbert_clf_together/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-macro: 0.6968, f1-micro: 0.7195\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in sbert_clf_together/pytorch_model.bin\n",
      "tokenizer config file saved in sbert_clf_together/tokenizer_config.json\n",
      "Special tokens file saved in sbert_clf_together/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on the  dataset after epoch 7:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in sbert_clf_together/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-macro: 0.7095, f1-micro: 0.7299\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in sbert_clf_together/pytorch_model.bin\n",
      "tokenizer config file saved in sbert_clf_together/tokenizer_config.json\n",
      "Special tokens file saved in sbert_clf_together/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "sbert_model.fit([(train_dataloader, triplet_loss), (train_dataloader, ce_loss)], show_progress_bar=True, epochs=8, \n",
    "          evaluator=evaluator, evaluation_steps=3000, output_path=\"sbert_clf_together\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import wandb\n",
    "wandb.init(project=\"Diploma\")\n",
    "\n",
    "torch.save(full_model.state_dict(), \"full/\")\n",
    "\n",
    "artifact = wandb.Artifact(\"sbert_clf_together\", type=\"model\")\n",
    "artifact.add_dir(\"full/\")\n",
    "wandb.log_artifact(artifact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценка качества SBERT + Classifier Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(huggingface_name)\n",
    "model = SBERTClassifier(sbert_model, clf_model)\n",
    "model.load_state_dict(torch.load('artifacts/sbert_clf_together'))\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.evaluate(test_dataset)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "03a864eb3fca49d28c4137fe02d58ae7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2615816b74c646549e505dc4a7dec4ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "358858abde724570a7c399788bdf321c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3c4c5131cb784aad8cd5de629dd8f05f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e09cdd38d9fd4aa4a4b122819c5ea95a",
      "placeholder": "​",
      "style": "IPY_MODEL_eb7f001689f64573a8ed59eab191f905",
      "value": " 590/590 [00:00&lt;00:00, 8.65kB/s]"
     }
    },
    "510bddf756a24cfba139b867b4e3e768": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_df7e31c5d043413582bc4d6aca33c019",
      "placeholder": "​",
      "style": "IPY_MODEL_90c3ef0a0e5643489494c8152e36671e",
      "value": " 1.78M/1.78M [00:00&lt;00:00, 13.9MB/s]"
     }
    },
    "52ee67c925164cf38e4670083f198042": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "86c833ab5cc94b48bd4715155df7c0a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_52ee67c925164cf38e4670083f198042",
      "max": 590,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cafcb0fd1bfb4b719528948792b3085a",
      "value": 590
     }
    },
    "8b235b206779411eb20b218a4205f944": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d5f384d864f94f11a9fa2937738cc217",
       "IPY_MODEL_8daae9ee040243419c4b09f109467d0b",
       "IPY_MODEL_510bddf756a24cfba139b867b4e3e768"
      ],
      "layout": "IPY_MODEL_f85bca21802b4d2c94dd215193c5154a"
     }
    },
    "8daae9ee040243419c4b09f109467d0b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_03a864eb3fca49d28c4137fe02d58ae7",
      "max": 1780720,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f9262b4f1bd3479db2cc6f9a21604aab",
      "value": 1780720
     }
    },
    "90c3ef0a0e5643489494c8152e36671e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bd8463df60be4238b745327ba33521e2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bf37d64f6085490d86f09c2bf38a01c4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cafcb0fd1bfb4b719528948792b3085a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d5f384d864f94f11a9fa2937738cc217": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bd8463df60be4238b745327ba33521e2",
      "placeholder": "​",
      "style": "IPY_MODEL_358858abde724570a7c399788bdf321c",
      "value": "Downloading: 100%"
     }
    },
    "da0c9f3d99534207b896ecf20bda36f1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df7e31c5d043413582bc4d6aca33c019": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e09cdd38d9fd4aa4a4b122819c5ea95a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e8cc0fe10ff8470fa60a1587540c88f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_da0c9f3d99534207b896ecf20bda36f1",
      "placeholder": "​",
      "style": "IPY_MODEL_2615816b74c646549e505dc4a7dec4ed",
      "value": "Downloading: 100%"
     }
    },
    "eb7f001689f64573a8ed59eab191f905": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f2c2d4c5f9044d2090d92832e589cbcf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e8cc0fe10ff8470fa60a1587540c88f5",
       "IPY_MODEL_86c833ab5cc94b48bd4715155df7c0a2",
       "IPY_MODEL_3c4c5131cb784aad8cd5de629dd8f05f"
      ],
      "layout": "IPY_MODEL_bf37d64f6085490d86f09c2bf38a01c4"
     }
    },
    "f85bca21802b4d2c94dd215193c5154a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9262b4f1bd3479db2cc6f9a21604aab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
